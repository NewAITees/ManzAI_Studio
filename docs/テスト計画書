# ManzAI Studio: AI主導テスト戦略

各開発工程後のテスト計画において、AIが最大限判断できるようにするための包括的なテスト戦略を提案します。人間の関与を総合テストのみに限定するため、以下のようなテスト自動化フレームワークを構築します。

## 1. 客観的評価指標の設定と自動化（3日間）

### 機能テスト自動化
```javascript
// tests/functional/test_api_endpoints.js
const { test, expect } = require('@playwright/test');

test('漫才生成エンドポイントが正常に動作する', async ({ request }) => {
  const response = await request.post('/api/generate', {
    data: {
      topic: 'テスト漫才',
      language: 'ja',
      length: 'short',
      tsukkomiSpeaker: 1,
      bokeSpeaker: 3
    }
  });
  
  expect(response.ok()).toBeTruthy();
  const data = await response.json();
  
  // データ構造の検証
  expect(data.script).toBeDefined();
  expect(data.script.length).toBeGreaterThan(0);
  expect(data.audio_data).toBeDefined();
  
  // 役割の検証
  const roles = data.script.map(line => line.role);
  expect(roles).toContain('tsukkomi');
  expect(roles).toContain('boke');
  
  // 音声ファイルの検証
  for (const audio of data.audio_data) {
    expect(audio.audio_path).toBeDefined();
    // 音声ファイルが存在するか検証
    const audioResponse = await request.get(`/api/audio/${audio.audio_path.split('/').pop()}`);
    expect(audioResponse.ok()).toBeTruthy();
  }
});
```

### 自動視覚評価システム
```python
# tests/visual/test_character_rendering.py
import cv2
import numpy as np
import pytest
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from PIL import Image
import io
import base64

class TestCharacterRendering:
    @pytest.fixture
    def browser(self):
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--window-size=1920,1080')
        driver = webdriver.Chrome(options=options)
        yield driver
        driver.quit()
    
    def test_character_rendering(self, browser):
        # アプリにアクセス
        browser.get('http://localhost:5173/display')
        
        # 背景色が正しいか検証（クロマキー用緑色）
        screenshot = browser.get_screenshot_as_png()
        img = Image.open(io.BytesIO(screenshot))
        img_array = np.array(img)
        
        # OpenCVでBGR形式に変換
        img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # 緑色検出（HSV色空間を使用）
        img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
        green_lower = np.array([40, 100, 100])
        green_upper = np.array([80, 255, 255])
        green_mask = cv2.inRange(img_hsv, green_lower, green_upper)
        
        # 緑色のピクセル率を計算
        green_percentage = (np.sum(green_mask > 0) / (green_mask.shape[0] * green_mask.shape[1])) * 100
        
        # 90%以上が緑色であるべき（キャラクターを除く）
        assert green_percentage > 90, f"緑色の背景が不十分: {green_percentage}%"
        
        # キャラクターが描画されていることを検証（緑色以外の領域）
        character_pixels = np.sum(green_mask == 0)
        assert character_pixels > 1000, "キャラクターが正しく描画されていません"
```

## 2. 音声品質とリップシンク評価の自動化（4日間）

### 音声トラック分析
```python
# tests/audio/test_voice_quality.py
import pytest
import numpy as np
import librosa
import requests
import tempfile
import os

class TestVoiceQuality:
    @pytest.fixture
    def generate_manzai(self):
        # 漫才を生成
        response = requests.post('http://localhost:5000/api/generate', json={
            'topic': '音声テスト',
            'language': 'ja',
            'length': 'short'
        })
        return response.json()
    
    def test_audio_quality(self, generate_manzai):
        data = generate_manzai
        
        for audio_item in data['audio_data']:
            # 音声ファイルをダウンロード
            audio_url = f"http://localhost:5000/api/audio/{os.path.basename(audio_item['audio_path'])}"
            audio_response = requests.get(audio_url)
            
            # 一時ファイルに保存
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp:
                temp.write(audio_response.content)
                temp_path = temp.name
            
            try:
                # librosaで音声を分析
                y, sr = librosa.load(temp_path, sr=None)
                
                # 1. 音声が空でないことを確認
                assert len(y) > 0, "音声データが空です"
                
                # 2. ビットレート確認
                assert sr >= 16000, f"サンプリングレートが低すぎます: {sr}Hz"
                
                # 3. 無音区間が少ないことを確認
                non_silent = librosa.effects.split(y, top_db=20)
                non_silent_duration = sum(end - start for start, end in non_silent) / sr
                total_duration = len(y) / sr
                non_silent_ratio = non_silent_duration / total_duration
                
                assert non_silent_ratio > 0.5, f"音声に無音区間が多すぎます: {non_silent_ratio:.2f}"
                
                # 4. 音量レベルの確認
                rms = librosa.feature.rms(y=y)[0]
                assert np.mean(rms) > 0.01, f"音量が低すぎます: {np.mean(rms):.4f}"
                
            finally:
                # 一時ファイルを削除
                os.unlink(temp_path)
```

### リップシンク同期性評価

```javascript
// tests/sync/test_lip_sync.js
const { test, expect } = require('@playwright/test');
const fs = require('fs').promises;
const path = require('path');

// リップシンク評価のテスト
test('リップシンクの同期性を評価する', async ({ page, browser }) => {
  // 1. アプリにアクセスし、漫才を生成
  await page.goto('http://localhost:5173');
  await page.fill('input[placeholder*="トピック"]', 'リップシンクテスト');
  await page.click('button:has-text("漫才を生成")');
  
  // 生成完了を待機
  await page.waitForSelector('button:has-text("再生")', { timeout: 60000 });
  
  // 2. 再生ボタンをクリック
  await page.click('button:has-text("再生")');
  
  // 3. キャプチャーを連続で取得して口の動きを分析
  const frames = [];
  const startTime = Date.now();
  const recordDuration = 5000; // 5秒間記録
  
  // CDPセッションを使用してブラウザのパフォーマンスメトリクスを取得
  const cdpSession = await page.context().newCDPSession(page);
  await cdpSession.send('Page.enable');
  
  // オーディオの再生開始時間を取得するためのJSイベントリスナー
  await page.evaluate(() => {
    window.audioStartTime = null;
    window.audioEvents = [];
    
    const audioElement = document.querySelector('audio');
    if (audioElement) {
      audioElement.addEventListener('play', () => {
        window.audioStartTime = performance.now();
        window.audioEvents.push({ type: 'play', time: performance.now() });
      });
      
      audioElement.addEventListener('timeupdate', () => {
        window.audioEvents.push({ 
          type: 'timeupdate', 
          time: performance.now(),
          currentTime: audioElement.currentTime
        });
      });
    }
  });
  
  // フレームを連続で取得
  while (Date.now() - startTime < recordDuration) {
    // スクリーンショットを取得
    const screenshot = await page.screenshot({ 
      clip: { x: 400, y: 200, width: 200, height: 200 } // キャラクターの口周辺を切り取り
    });
    
    // 現在の時間を記録
    const timestamp = Date.now() - startTime;
    
    // フレームを保存
    frames.push({ timestamp, screenshot });
    
    // 50ms待機（約20fps）
    await page.waitForTimeout(50);
  }
  
  // 4. オーディオイベントを取得
  const audioEvents = await page.evaluate(() => window.audioEvents);
  
  // 5. 画像分析とオーディオイベントの相関を評価
  const mouthStateChanges = analyzeMouthMovements(frames);
  const audioTimeUpdates = audioEvents.filter(e => e.type === 'timeupdate');
  
  // 口の動きとオーディオの同期性を評価
  let syncScore = 0;
  let totalComparisons = 0;
  
  for (const mouthChange of mouthStateChanges) {
    // 最も近いオーディオイベントを見つける
    const closestAudioEvent = findClosestAudioEvent(mouthChange.timestamp, audioTimeUpdates);
    if (closestAudioEvent) {
      // タイムスタンプの差が100ms以内であれば同期していると判断
      const timeDiff = Math.abs(mouthChange.timestamp - (closestAudioEvent.time - audioEvents[0].time));
      if (timeDiff < 100) {
        syncScore++;
      }
      totalComparisons++;
    }
  }
  
  const syncPercentage = totalComparisons > 0 ? (syncScore / totalComparisons) * 100 : 0;
  console.log(`リップシンク同期率: ${syncPercentage.toFixed(2)}%`);
  
  // 70%以上の同期率を期待
  expect(syncPercentage).toBeGreaterThanOrEqual(70);
});

// ヘルパー関数（実際の実装では画像処理ライブラリを使用）
function analyzeMouthMovements(frames) {
  // 実際の実装では、画像処理により口の開閉状態を分析
  // このサンプルでは単純化のためダミー実装
  const changes = [];
  let prevMouthState = null;
  
  for (const frame of frames) {
    // 画像処理によって口の開閉状態を検出（0〜1の値）
    const mouthState = detectMouthOpenness(frame.screenshot);
    
    // 状態に大きな変化があった場合に記録
    if (prevMouthState !== null && Math.abs(mouthState - prevMouthState) > 0.3) {
      changes.push({
        timestamp: frame.timestamp,
        from: prevMouthState,
        to: mouthState
      });
    }
    
    prevMouthState = mouthState;
  }
  
  return changes;
}

function findClosestAudioEvent(timestamp, audioEvents) {
  return audioEvents.reduce((closest, event) => {
    const eventTime = event.time - audioEvents[0].time;
    const currentDiff = Math.abs(timestamp - eventTime);
    const closestDiff = closest ? Math.abs(timestamp - (closest.time - audioEvents[0].time)) : Infinity;
    
    return currentDiff < closestDiff ? event : closest;
  }, null);
}

function detectMouthOpenness(imageBuffer) {
  // 実際の実装では画像処理により口の開閉度を検出
  // このサンプルではダミー値を返す
  return Math.random();
}
```

## 3. 漫才コンテンツ品質の自動評価（4日間）

### 漫才スクリプト分析器
```python
# tests/content/test_manzai_quality.py
import pytest
import requests
import re
import json
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

class TestManzaiQuality:
    @pytest.fixture(scope="module")
    def nlp_models(self):
        # 感情分析モデル
        nltk.download('vader_lexicon')
        sentiment_analyzer = SentimentIntensityAnalyzer()
        
        # テキスト品質評価モデル
        tokenizer = AutoTokenizer.from_pretrained("bert-base-multilingual-cased")
        model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
        quality_analyzer = pipeline("text-classification", model=model, tokenizer=tokenizer)
        
        return {
            "sentiment": sentiment_analyzer,
            "quality": quality_analyzer
        }
    
    @pytest.fixture
    def generate_multiple_manzai(self):
        results = []
        topics = ["猫", "旅行", "テクノロジー", "食べ物", "スポーツ"]
        
        for topic in topics:
            response = requests.post('http://localhost:5000/api/generate', json={
                'topic': topic,
                'language': 'ja',
                'length': 'medium'
            })
            results.append(response.json())
        
        return results
    
    def test_dialogue_structure(self, generate_multiple_manzai):
        for manzai_data in generate_multiple_manzai:
            script = manzai_data['script']
            
            # 1. 役割交替の検証
            for i in range(1, len(script)):
                prev_role = script[i-1]['role']
                curr_role = script[i]['role']
                
                # 同じ役割が連続しないことを期待（基本的に交互）
                assert prev_role != curr_role, f"同じ役割が連続しています: {prev_role}, {curr_role}"
            
            # 2. 漫才の長さ検証
            assert len(script) >= 6, f"漫才が短すぎます: {len(script)}行"
            
            # 3. 会話のつながりを検証
            for i in range(1, len(script)):
                prev_text = script[i-1]['text']
                curr_text = script[i]['text']
                
                # 会話の一貫性を簡易的に評価（返答に前の発言の単語が含まれるか）
                prev_keywords = self.extract_keywords(prev_text)
                has_connection = any(keyword in curr_text for keyword in prev_keywords if len(keyword) > 1)
                
                assert has_connection, f"会話の一貫性がありません: \n前: {prev_text}\n後: {curr_text}"
    
    def test_content_sentiment(self, generate_multiple_manzai, nlp_models):
        sentiment_analyzer = nlp_models["sentiment"]
        
        for manzai_data in generate_multiple_manzai:
            script = manzai_data['script']
            full_text = " ".join([line['text'] for line in script])
            
            # 感情分析スコアを取得
            sentiment_scores = sentiment_analyzer.polarity_scores(full_text)
            
            # 漫才の基本はポジティブか中立であるべき
            assert sentiment_scores['compound'] >= -0.3, f"漫才の感情がネガティブすぎます: {sentiment_scores}"
            
            # ユーモアの指標として、ボケのセリフはポジティブ傾向があるべき
            boke_lines = [line['text'] for line in script if line['role'] == 'boke']
            boke_text = " ".join(boke_lines)
            boke_sentiment = sentiment_analyzer.polarity_scores(boke_text)
            
            assert boke_sentiment['pos'] > 0.1, f"ボケのセリフがポジティブさに欠けています: {boke_sentiment}"
    
    def extract_keywords(self, text):
        # 簡易的なキーワード抽出（実際はより高度な形態素解析を使用）
        words = re.findall(r'\w+', text)
        return [word for word in words if len(word) > 1]
```

## 4. デュアルウィンドウとクロマキー対応の検証（3日間）

### ウィンドウ間通信テスト
```javascript
// tests/window/test_dual_window.js
const { test, expect } = require('@playwright/test');

test('デュアルウィンドウモードが正常に機能する', async ({ browser }) => {
  // 1. メインウィンドウを起動
  const mainContext = await browser.newContext();
  const mainPage = await mainContext.newPage();
  await mainPage.goto('http://localhost:5173');
  
  // 2. 表示ウィンドウを開くボタンをクリック
  await mainPage.click('button:has-text("表示ウィンドウを開く")');
  
  // 3. 新しいウィンドウが開くのを待機
  const pagePromise = mainContext.waitForEvent('page');
  const displayPage = await pagePromise;
  await displayPage.waitForLoadState();
  
  // 4. 表示ウィンドウが正しいURLで開かれたか確認
  expect(displayPage.url()).toContain('/display');
  
  // 5. メインウィンドウで漫才を生成
  await mainPage.fill('input[placeholder*="トピック"]', 'ウィンドウテスト');
  await mainPage.click('button:has-text("漫才を生成")');
  
  // 生成完了を待機
  await mainPage.waitForSelector('button:has-text("再生")', { timeout: 60000 });
  
  // 6. メインウィンドウで再生ボタンをクリック
  await mainPage.click('button:has-text("再生")');
  
  // 7. 両方のウィンドウでキャラクターの口が動くことを確認
  const checkMouthAnimation = async (page) => {
    // スクリーンショットを複数回取得して比較
    const screenshots = [];
    
    for (let i = 0; i < 5; i++) {
      await page.waitForTimeout(300);
      screenshots.push(await page.screenshot());
    }
    
    // スクリーンショットに違いがあるかを検証（口が動いていれば異なる）
    let hasDifferences = false;
    
    for (let i = 1; i < screenshots.length; i++) {
      if (!screenshotsEqual(screenshots[i-1], screenshots[i])) {
        hasDifferences = true;
        break;
      }
    }
    
    return hasDifferences;
  };
  
  // メインウィンドウのアニメーション確認
  const mainWindowAnimated = await checkMouthAnimation(mainPage);
  expect(mainWindowAnimated).toBeTruthy();
  
  // 表示ウィンドウのアニメーション確認
  const displayWindowAnimated = await checkMouthAnimation(displayPage);
  expect(displayWindowAnimated).toBeTruthy();
  
  // 8. メインウィンドウの操作が表示ウィンドウに反映されるか検証
  // 停止ボタンをクリック
  await mainPage.click('button:has-text("停止")');
  await mainPage.waitForTimeout(500);
  
  // 両方のウィンドウでアニメーションが停止したか確認
  const mainWindowStopped = !(await checkMouthAnimation(mainPage));
  const displayWindowStopped = !(await checkMouthAnimation(displayPage));
  
  expect(mainWindowStopped).toBeTruthy();
  expect(displayWindowStopped).toBeTruthy();
});

// ヘルパー関数: スクリーンショットが同一かを判定
function screenshotsEqual(buffer1, buffer2) {
  // 実際の実装では画像比較ライブラリを使用
  // このサンプルでは単純なバッファー比較
  return buffer1.toString('base64') === buffer2.toString('base64');
}
```

### クロマキー背景テスト
```javascript
// tests/visual/test_chroma_key.js
const { test, expect } = require('@playwright/test');
const fs = require('fs').promises;
const { createCanvas, loadImage } = require('canvas');
const chroma = require('chroma-js');

test('クロマキー背景が正しく機能する', async ({ page }) => {
  // 1. 表示専用ページにアクセス
  await page.goto('http://localhost:5173/display');
  
  // 2. スクリーンショットを取得
  const screenshot = await page.screenshot();
  
  // 3. スクリーンショットを解析して背景色を検証
  const image = await loadImage(screenshot);
  const canvas = createCanvas(image.width, image.height);
  const ctx = canvas.getContext('2d');
  ctx.drawImage(image, 0, 0);
  
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const pixels = imageData.data;
  
  // 緑色のピクセル数をカウント
  let greenPixels = 0;
  let totalPixels = 0;
  
  for (let i = 0; i < pixels.length; i += 4) {
    const r = pixels[i];
    const g = pixels[i + 1];
    const b = pixels[i + 2];
    
    // RGB値をHSLに変換して緑色を判定（緑色の範囲を広めに取る）
    const color = chroma([r, g, b]);
    const hsl = color.hsl();
    
    // HSLの色相で緑色の範囲を指定（90〜150度）
    if (hsl[0] >= 90 && hsl[0] <= 150 && hsl[1] >= 0.5) {
      greenPixels++;
    }
    
    totalPixels++;
  }
  
  const greenPercentage = (greenPixels / totalPixels) * 100;
  console.log(`緑色背景の割合: ${greenPercentage.toFixed(2)}%`);
  
  // 背景の大部分が緑色であることを検証（キャラクターを除く）
  expect(greenPercentage).toBeGreaterThan(80);
  
  // 4. 画面上にUIコントロールが表示されていないことを検証
  const formElements = await page.$$('form, button, input, select');
  expect(formElements.length).toBe(0);
});
```

## 5. 音声出力デバイス選択テスト（2日間）

```javascript
// tests/audio/test_audio_device_selection.js
const { test, expect } = require('@playwright/test');

test('音声出力デバイス選択が正常に機能する', async ({ page }) => {
  // 1. アプリにアクセス
  await page.goto('http://localhost:5173');
  
  // 2. 音声出力デバイスが取得されるか検証
  const deviceSelector = await page.$('select[name="audioDevice"]');
  expect(deviceSelector).not.toBeNull();
  
  // 3. JSの権限をテストするためのモック
  await page.evaluate(() => {
    // MediaDevices APIをモック
    if (!navigator.mediaDevices) {
      navigator.mediaDevices = {};
    }
    
    const originalEnumerateDevices = navigator.mediaDevices.enumerateDevices;
    
    // オーディオ出力デバイスを含む結果を返すモック
    navigator.mediaDevices.enumerateDevices = async () => {
      return [
        {
          deviceId: 'default',
          kind: 'audiooutput',
          label: 'Default'
        },
        {
          deviceId: 'device1',
          kind: 'audiooutput',
          label: 'Speaker 1'
        },
        {
          deviceId: 'device2',
          kind: 'audiooutput',
          label: 'Speaker 2'
        }
      ];
    };
    
    // AudioElement.setSinkIdをモック
    HTMLAudioElement.prototype.setSinkId = async function(deviceId) {
      this.dataset.sinkId = deviceId;
      return Promise.resolve();
    };
    
    // 後で検証できるように選択されたデバイスを記録
    window.selectedAudioDevice = null;
  });
  
  // 4. ページをリロードしてモックを適用
  await page.reload();
  
  // 5. デバイスが選択肢に表示されるか確認
  await page.waitForSelector('select[name="audioDevice"]');
  const options = await page.$$eval('select[name="audioDevice"] option', options => {
    return options.map(option => option.value);
  });
  
  expect(options).toContain('default');
  expect(options).toContain('device1');
  expect(options).toContain('device2');
  
  // 6. デバイスを選択して設定が適用されるか検証
  await page.selectOption('select[name="audioDevice"]', 'device2');
  
  // 7. 漫才を生成して再生
  await page.fill('input[placeholder*="トピック"]', 'オーディオテスト');
  await page.click('button:has-text("漫才を生成")');
  
  // 生成完了を待機
  await page.waitForSelector('button:has-text("再生")', { timeout: 60000 });
  
  // 8. 再生ボタンをクリック
  await page.click('button:has-text("再生")');
  
  // 9. 選択したデバイスが適用されたか確認
  const deviceApplied = await page.evaluate(() => {
    const audioElement = document.querySelector('audio');
    return audioElement ? audioElement.dataset.sinkId === 'device2' : false;
  });
  
  expect(deviceApplied).toBeTruthy();
  
  // 10. ローカルストレージに設定が保存されたか確認
  const savedSettings = await page.evaluate(() => {
    return JSON.parse(localStorage.getItem('manzai-studio-settings'));
  });
  
  expect(savedSettings).toHaveProperty('audioDevice', 'device2');
});
```

## 6. 統合テスト自動化フレームワーク（4日間）

### テスト自動化サーバー

```python
# tools/test_automation_server.py
import os
import sys
import json
import subprocess
import time
import logging
from flask import Flask, jsonify, request
from threading import Thread

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# テスト実行ステータス
test_status = {
    "running": False,
    "current_test": None,
    "results": {},
    "logs": []
}

def run_tests(test_suites):
    """指定されたテストスイートを実行する"""
    global test_status
    
    test_status["running"] = True
    test_status["logs"] = []
    test_status["results"] = {}
    
    try:
        # 1. バックエンドサーバーを起動
        logging.info("バックエンドサーバーを起動中...")
        backend_process = subprocess.Popen(
            ["python", "run.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # サーバー起動を待機
        time.sleep(5)
        
        # 2. フロントエンドサーバーを起動
        logging.info("フロントエンドサーバーを起動中...")
        frontend_process = subprocess.Popen(
            ["npm", "run", "dev"],
            cwd="frontend",
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # サーバー起動を待機
        time.sleep(5)
        
        # 3. テストスイートを順番に実行
        for suite in test_suites:
            test_status["current_test"] = suite
            logging.info(f"テストスイート実行中: {suite}")
            
            if suite.endswith(".py"):
                # Pythonテスト
                result = subprocess.run(
                    ["pytest", suite, "-v"],
                    capture_output=True,
                    text=True
                )
            else:
                # JavaScriptテスト
                result = subprocess.run(
                    ["npx", "playwright", "test", suite],
                    cwd="frontend",
                    capture_output=True,
                    text=True
                )
            
            # 結果を保存
            test_status["results"][suite] = {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr
            }
            
            test_status["logs"].append(f"テストスイート {suite} 完了: {'成功' if result.returncode == 0 else '失敗'}")
        
    except Exception as e:
        logging.error(f"テスト実行中にエラーが発生: {e}")
        test_status["logs"].append(f"エラー: {e}")
    finally:
        # プロセスを終了
        if 'backend_process' in locals():
            backend_process.terminate()
        
        if 'frontend_process' in locals():
            frontend_process.terminate()
        
        test_status["running"] = False
        test_status["current_test"] = None
        logging.info("テスト実行完了")

@app.route('/api/run-tests', methods=['POST'])
def api_run_tests():
    """テスト実行APIエンドポイント"""
    if test_status["running"]:
        return jsonify({"error": "テストがすでに実行中です"}), 400
    
    # リクエストからテストスイートを取得
    data = request.get_json()
    test_suites = data.get('test_suites', [])
    
    if not test_suites:
        return jsonify({"error": "テストスイートが指定されていません"}), 400
    
    # 別スレッドでテストを実行
    thread = Thread(target=run_tests, args=(test_suites,))
    thread.start()
    
    return jsonify({"message": "テスト実行を開始しました"})

@app.route('/api/test-status', methods=['GET'])
def api_test_status():
    """テスト状態取得APIエンドポイント"""
    return jsonify(test_status)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5050)
```

### 自動テストダッシュボード

```html
<!-- tools/test_dashboard.html -->
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ManzAI Studio 自動テストダッシュボード</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        pre {
            background-color: #f5f5f5;
            padding: 10px;
            border-radius: 5px;
            max-height: 400px;
            overflow-y: auto;
        }
        .test-card {
            margin-bottom: 15px;
        }
        .log-container {
            height: 200px;
            overflow-y: auto;
            background-color: #f5f5f5;
            padding: 10px;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <div class="container mt-4">
        <h1>ManzAI Studio 自動テストダッシュボード</h1>
        
        <div class="row mt-4">
            <div class="col-md-6">
                <div class="card">
                    <div class="card-header">
                        テスト実行
                    </div>
                    <div class="card-body">
                        <form id="testForm">
                            <div class="mb-3">
                                <label class="form-label">テストスイート選択</label>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/functional/test_api_endpoints.js" id="testApi" checked>
                                    <label class="form-check-label" for="testApi">
                                        APIエンドポイントテスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/visual/test_character_rendering.py" id="testRendering" checked>
                                    <label class="form-check-label" for="testRendering">
                                        キャラクターレンダリングテスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/audio/test_voice_quality.py" id="testVoice" checked>
                                    <label class="form-check-label" for="testVoice">
                                        音声品質テスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/sync/test_lip_sync.js" id="testSync" checked>
                                    <label class="form-check-label" for="testSync">
                                        リップシンクテスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/content/test_manzai_quality.py" id="testContent" checked>
                                    <label class="form-check-label" for="testContent">
                                        漫才コンテンツ品質テスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/window/test_dual_window.js" id="testWindow" checked>
                                    <label class="form-check-label" for="testWindow">
                                        デュアルウィンドウテスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/visual/test_chroma_key.js" id="testChroma" checked>
                                    <label class="form-check-label" for="testChroma">
                                        クロマキー背景テスト
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="checkbox" value="tests/audio/test_audio_device_selection.js" id="testAudioDevice" checked>
                                    <label class="form-check-label" for="testAudioDevice">
                                        音声出力デバイス選択テスト
                                    </label>
                                </div>
                            </div>
                            <button type="submit" class="btn btn-primary" id="runTestsBtn">テスト実行</button>
                        </form>
                    </div>
                </div>
                
                <div class="card mt-4">
                    <div class="card-header">
                        実行ログ
                    </div>
                    <div class="card-body">
                        <div class="log-container" id="logContainer">
                            <!-- 実行ログがここに表示される -->
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="col-md-6">
                <div class="card">
                    <div class="card-header">
                        テスト結果
                    </div>
                    <div class="card-body">
                        <div id="resultContainer">
                            <!-- テスト結果がここに表示される -->
                            <p class="text-muted">テストを実行すると結果がここに表示されます。</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const testForm = document.getElementById('testForm');
            const runTestsBtn = document.getElementById('runTestsBtn');
            const logContainer = document.getElementById('logContainer');
            const resultContainer = document.getElementById('resultContainer');
            
            let statusCheckInterval = null;
            
            // テスト実行フォーム送信
            testForm.addEventListener('submit', function(e) {
                e.preventDefault();
                
                // 選択されたテストスイート
                const checkboxes = document.querySelectorAll('input[type="checkbox"]:checked');
                const testSuites = Array.from(checkboxes).map(cb => cb.value);
                
                if (testSuites.length === 0) {
                    alert('テストスイートを選択してください');
                    return;
                }
                
                // ボタンを無効化
                runTestsBtn.disabled = true;
                runTestsBtn.innerHTML = '<span class="spinner-border spinner-border-sm" role="status" aria-hidden="true"></span> テスト実行中...';
                
                // テスト実行リクエスト
                fetch('http://localhost:5050/api/run-tests', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ test_suites: testSuites }),
                })
                .then(response => response.json())
                .then(data => {
                    logContainer.innerHTML = `<p>${data.message}</p>`;
                    
                    // 定期的にステータスをチェック
                    statusCheckInterval = setInterval(checkStatus, 1000);
                })
                .catch(error => {
                    logContainer.innerHTML += `<p class="text-danger">エラー: ${error}</p>`;
                    runTestsBtn.disabled = false;
                    runTestsBtn.innerHTML = 'テスト実行';
                });
            });
            
            // テストステータスチェック
            function checkStatus() {
                fetch('http://localhost:5050/api/test-status')
                .then(response => response.json())
                .then(data => {
                    // ログを更新
                    logContainer.innerHTML = '';
                    data.logs.forEach(log => {
                        logContainer.innerHTML += `<p>${log}</p>`;
                    });
                    
                    // 自動スクロール
                    logContainer.scrollTop = logContainer.scrollHeight;
                    
                    // テスト完了時
                    if (!data.running && data.logs.length > 0) {
                        clearInterval(statusCheckInterval);
                        runTestsBtn.disabled = false;
                        runTestsBtn.innerHTML = 'テスト実行';
                        
                        // 結果を表示
                        displayResults(data.results);
                    }
                })
                .catch(error => {
                    logContainer.innerHTML += `<p class="text-danger">ステータス取得エラー: ${error}</p>`;
                });
            }
            
            // テスト結果表示
            function displayResults(results) {
                resultContainer.innerHTML = '';
                
                if (Object.keys(results).length === 0) {
                    resultContainer.innerHTML = '<p class="text-muted">テスト結果がありません。</p>';
                    return;
                }
                
                for (const [suite, result] of Object.entries(results)) {
                    const cardClass = result.success ? 'border-success' : 'border-danger';
                    const headerClass = result.success ? 'bg-success text-white' : 'bg-danger text-white';
                    
                    const card = document.createElement('div');
                    card.className = `card ${cardClass} test-card`;
                    
                    const header = document.createElement('div');
                    header.className = `card-header ${headerClass}`;
                    header.innerText = `${suite} - ${result.success ? '成功' : '失敗'}`;
                    
                    const body = document.createElement('div');
                    body.className = 'card-body';
                    
                    const accordion = document.createElement('div');
                    accordion.className = 'accordion';
                    accordion.id = `accordion-${suite.replace(/[^a-zA-Z0-9]/g, '')}`;
                    
                    // 出力詳細アコーディオン
                    accordion.innerHTML = `
                        <div class="accordion-item">
                            <h2 class="accordion-header">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse-${suite.replace(/[^a-zA-Z0-9]/g, '')}">
                                    出力の詳細
                                </button>
                            </h2>
                            <div id="collapse-${suite.replace(/[^a-zA-Z0-9]/g, '')}" class="accordion-collapse collapse">
                                <div class="accordion-body">
                                    <strong>標準出力:</strong>
                                    <pre>${result.stdout}</pre>
                                    <strong>標準エラー:</strong>
                                    <pre>${result.stderr}</pre>
                                </div>
                            </div>
                        </div>
                    `;
                    
                    body.appendChild(accordion);
                    card.appendChild(header);
                    card.appendChild(body);
                    resultContainer.appendChild(card);
                }
            }
        });
    </script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
```

## 自動化テスト戦略のメリット

この自動テスト戦略により、以下の点で人間の判断を最小限に抑えることができます：

1. **視覚的評価の数値化**：
   - 画像処理アルゴリズムによるキャラクターの描画検証
   - クロマキー背景色の正確な測定
   - リップシンク同期性の定量的評価

2. **音声品質の客観的指標**：
   - 音声ファイルの技術的品質（サンプリングレート、無音区間、音量）の自動検証
   - 出力デバイス制御の検証

3. **コンテンツ品質の自動評価**：
   - 自然言語処理による漫才スクリプトの構造分析
   - 感情分析による漫才のポジティブ性評価
   - 会話の一貫性の自動検証

4. **ユーザーインターフェースの検証**：
   - デュアルウィンドウモードの機能検証
   - UI表示/非表示の自動確認
   - キーボードショートカットの動作検証

5. **テスト自動化サーバー**：
   - 全テストスイートの自動実行と結果集計
   - 分かりやすいダッシュボード表示
   - 問題箇所の自動特定

## 人間による総合テストの最適化

人間による総合テストは、以下の点に集中させることで効率化できます：

1. 漫才コンテンツの「面白さ」や「自然さ」の主観的評価
2. 実際の配信環境での使用感
3. クロマキー合成した際の視覚的な品質（実際の配信ソフトで）
4. 思わぬユースケースや想定外の操作に対する耐性

**すべての技術的評価はAIテスト自動化フレームワークが行い、人間は主観的な品質と実用性の検証のみに集中できます。**

この戦略により、開発チームは開発に集中し、人間のテスターは本当に人間の判断が必要な部分にのみ時間を使うことができるようになります。




"""
ManzAI Studio Test Automation Framework

This framework provides a comprehensive set of automated tests for the ManzAI Studio application,
covering functional testing, visual evaluation, audio quality, lip sync, content quality,
and dual window/chroma key testing.
"""

import os
import sys
import json
import time
import logging
import subprocess
import threading
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass
import signal
import requests
from flask import Flask, jsonify, request
import pytest

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("test_automation.log")
    ]
)
logger = logging.getLogger("manzai_test_automation")

# Constants
BACKEND_HOST = "localhost"
BACKEND_PORT = 5000
FRONTEND_HOST = "localhost"
FRONTEND_PORT = 5173
AUTOMATION_SERVER_PORT = 5050

@dataclass
class TestResult:
    """Represents the result of a test execution."""
    test_name: str
    success: bool
    stdout: str
    stderr: str
    execution_time: float


class TestProcess:
    """Manages the execution of a test process."""
    
    def __init__(self, command: List[str], cwd: Optional[str] = None):
        self.command = command
        self.cwd = cwd
        self.process = None
        self.stdout = ""
        self.stderr = ""
        self.start_time = 0
        self.end_time = 0
        
    def run(self) -> TestResult:
        """Run the test process and return the result."""
        logger.info(f"Running command: {' '.join(self.command)}")
        self.start_time = time.time()
        
        try:
            self.process = subprocess.Popen(
                self.command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=self.cwd
            )
            
            self.stdout, self.stderr = self.process.communicate()
            self.end_time = time.time()
            
            success = self.process.returncode == 0
            execution_time = self.end_time - self.start_time
            
            logger.info(f"Command completed with status: {'Success' if success else 'Failure'}")
            logger.debug(f"Stdout: {self.stdout}")
            logger.debug(f"Stderr: {self.stderr}")
            
            return TestResult(
                test_name=' '.join(self.command),
                success=success,
                stdout=self.stdout,
                stderr=self.stderr,
                execution_time=execution_time
            )
            
        except Exception as e:
            logger.error(f"Error running command: {e}")
            return TestResult(
                test_name=' '.join(self.command),
                success=False,
                stdout="",
                stderr=str(e),
                execution_time=time.time() - self.start_time
            )


class ServerProcess:
    """Manages a server process (backend or frontend)."""
    
    def __init__(self, name: str, command: List[str], cwd: Optional[str] = None, 
                 ready_message: Optional[str] = None, health_url: Optional[str] = None):
        self.name = name
        self.command = command
        self.cwd = cwd
        self.ready_message = ready_message
        self.health_url = health_url
        self.process = None
        self.stdout_lines = []
        self.stderr_lines = []
        self._stop_threads = False
        self._stdout_thread = None
        self._stderr_thread = None
        
    def _read_stream(self, stream, lines_list):
        """Read from a stream and store lines."""
        while not self._stop_threads:
            line = stream.readline()
            if not line:
                break
            line_str = line.decode('utf-8') if isinstance(line, bytes) else line
            logger.debug(f"{self.name} {stream.name}: {line_str.strip()}")
            lines_list.append(line_str)
            
            if self.ready_message and self.ready_message in line_str:
                logger.info(f"{self.name} ready message detected: {self.ready_message}")
                
    def start(self) -> bool:
        """Start the server process."""
        logger.info(f"Starting {self.name} with command: {' '.join(self.command)}")
        
        try:
            self.process = subprocess.Popen(
                self.command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=self.cwd
            )
            
            # Start threads to read stdout and stderr
            self._stop_threads = False
            self._stdout_thread = threading.Thread(
                target=self._read_stream, 
                args=(self.process.stdout, self.stdout_lines)
            )
            self._stderr_thread = threading.Thread(
                target=self._read_stream, 
                args=(self.process.stderr, self.stderr_lines)
            )
            
            self._stdout_thread.daemon = True
            self._stderr_thread.daemon = True
            self._stdout_thread.start()
            self._stderr_thread.start()
            
            # Wait for server to be ready
            if self.ready_message:
                start_time = time.time()
                while time.time() - start_time < 30:  # 30 seconds timeout
                    if any(self.ready_message in line for line in self.stdout_lines):
                        logger.info(f"{self.name} is ready")
                        return True
                    if self.process.poll() is not None:
                        logger.error(f"{self.name} process exited prematurely with code {self.process.returncode}")
                        return False
                    time.sleep(0.1)
                
                logger.error(f"Timeout waiting for {self.name} ready message")
                return False
            
            if self.health_url:
                start_time = time.time()
                while time.time() - start_time < 30:  # 30 seconds timeout
                    try:
                        response = requests.get(self.health_url, timeout=1)
                        if response.status_code == 200:
                            logger.info(f"{self.name} health check passed")
                            return True
                    except requests.RequestException:
                        pass
                    
                    if self.process.poll() is not None:
                        logger.error(f"{self.name} process exited prematurely with code {self.process.returncode}")
                        return False
                    
                    time.sleep(0.5)
                
                logger.error(f"Timeout waiting for {self.name} health check")
                return False
            
            # If no ready check is specified, just assume it started successfully
            return True
            
        except Exception as e:
            logger.error(f"Error starting {self.name}: {e}")
            return False
    
    def stop(self):
        """Stop the server process."""
        if self.process:
            logger.info(f"Stopping {self.name}")
            
            # Stop the reading threads
            self._stop_threads = True
            
            # Send SIGTERM
            self.process.terminate()
            
            # Wait for process to terminate
            try:
                self.process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                logger.warning(f"{self.name} did not terminate in time, forcing kill")
                self.process.kill()
            
            # Wait for threads to finish
            if self._stdout_thread and self._stdout_thread.is_alive():
                self._stdout_thread.join(timeout=2)
            
            if self._stderr_thread and self._stderr_thread.is_alive():
                self._stderr_thread.join(timeout=2)
                
            logger.info(f"{self.name} stopped")


class TestServer:
    """Flask server for test automation."""
    
    def __init__(self, port: int = AUTOMATION_SERVER_PORT):
        self.port = port
        self.app = Flask(__name__)
        self.test_status = {
            "running": False,
            "current_test": None,
            "results": {},
            "logs": []
        }
        
        # Setup routes
        self.app.route('/api/run-tests', methods=['POST'])(self.api_run_tests)
        self.app.route('/api/test-status', methods=['GET'])(self.api_test_status)
        
        # Reference to test runner thread
        self.test_runner_thread = None
    
    def api_run_tests(self):
        """API endpoint to run tests."""
        if self.test_status["running"]:
            return jsonify({"error": "Tests are already running"}), 400
        
        # Get test suites from request
        data = request.get_json()
        test_suites = data.get('test_suites', [])
        
        if not test_suites:
            return jsonify({"error": "No test suites specified"}), 400
        
        # Start test runner in a separate thread
        self.test_runner_thread = threading.Thread(
            target=self.run_tests,
            args=(test_suites,)
        )
        self.test_runner_thread.daemon = True
        self.test_runner_thread.start()
        
        return jsonify({"message": "Test execution started"})
    
    def api_test_status(self):
        """API endpoint to get test status."""
        return jsonify(self.test_status)
    
    def run_tests(self, test_suites: List[str]):
        """Run the specified test suites."""
        self.test_status["running"] = True
        self.test_status["current_test"] = None
        self.test_status["results"] = {}
        self.test_status["logs"] = []
        
        # Log start of test execution
        log_message = f"Starting test execution for {len(test_suites)} suites"
        logger.info(log_message)
        self.test_status["logs"].append(log_message)
        
        # Start backend and frontend servers
        backend_server = ServerProcess(
            name="Backend",
            command=["python", "run.py"],
            health_url=f"http://{BACKEND_HOST}:{BACKEND_PORT}/api/health"
        )
        
        frontend_server = ServerProcess(
            name="Frontend",
            command=["npm", "run", "dev"],
            cwd="frontend",
            ready_message="Local:   http://localhost:"
        )
        
        try:
            # Start backend
            log_message = "Starting backend server..."
            logger.info(log_message)
            self.test_status["logs"].append(log_message)
            
            if not backend_server.start():
                log_message = "Failed to start backend server"
                logger.error(log_message)
                self.test_status["logs"].append(log_message)
                return
            
            # Start frontend
            log_message = "Starting frontend server..."
            logger.info(log_message)
            self.test_status["logs"].append(log_message)
            
            if not frontend_server.start():
                log_message = "Failed to start frontend server"
                logger.error(log_message)
                self.test_status["logs"].append(log_message)
                return
            
            # Wait a bit to ensure servers are fully ready
            time.sleep(5)
            
            # Run each test suite
            for test_suite in test_suites:
                self.test_status["current_test"] = test_suite
                log_message = f"Running test suite: {test_suite}"
                logger.info(log_message)
                self.test_status["logs"].append(log_message)
                
                if test_suite.endswith(".py"):
                    # Python test
                    test_process = TestProcess(
                        command=["pytest", test_suite, "-v"]
                    )
                else:
                    # JavaScript test
                    test_process = TestProcess(
                        command=["npx", "playwright", "test", test_suite],
                        cwd="frontend"
                    )
                
                # Run the test
                test_result = test_process.run()
                
                # Store results
                self.test_status["results"][test_suite] = {
                    "success": test_result.success,
                    "stdout": test_result.stdout,
                    "stderr": test_result.stderr,
                    "execution_time": test_result.execution_time
                }
                
                # Log test completion
                log_message = f"Test suite {test_suite} completed: {'Success' if test_result.success else 'Failure'}"
                logger.info(log_message)
                self.test_status["logs"].append(log_message)
                
        finally:
            # Stop servers
            log_message = "Stopping servers..."
            logger.info(log_message)
            self.test_status["logs"].append(log_message)
            
            backend_server.stop()
            frontend_server.stop()
            
            # Mark test execution as complete
            self.test_status["running"] = False
            self.test_status["current_test"] = None
            
            log_message = "Test execution completed"
            logger.info(log_message)
            self.test_status["logs"].append(log_message)
    
    def run(self):
        """Run the test server."""
        logger.info(f"Starting test automation server on port {self.port}")
        self.app.run(host='0.0.0.0', port=self.port)


class TestRunner:
    """Main class for running tests."""
    
    def __init__(self):
        self.test_server = TestServer()
    
    def run(self):
        """Run the test automation server."""
        self.test_server.run()


# Test suite classes
class FunctionalTests:
    """API and functional tests for ManzAI Studio."""
    
    @staticmethod
    def test_api_endpoints():
        """Test the API endpoints."""
        response = requests.get(f"http://{BACKEND_HOST}:{BACKEND_PORT}/api/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
        
        # Test manzai generation
        response = requests.post(
            f"http://{BACKEND_HOST}:{BACKEND_PORT}/api/generate",
            json={"topic": "テスト漫才"}
        )
        assert response.status_code == 200
        assert "script" in response.json()


class VisualTests:
    """Visual and rendering tests for ManzAI Studio."""
    
    @staticmethod
    def test_character_rendering():
        """Test character rendering on the display page."""
        # This would typically be implemented using Playwright or Selenium
        # For demonstration purposes, we'll use a placeholder implementation
        pass


class AudioTests:
    """Audio quality tests for ManzAI Studio."""
    
    @staticmethod
    def test_voice_quality():
        """Test the quality of generated voice audio."""
        # This would typically be implemented using librosa or other audio analysis libraries
        # For demonstration purposes, we'll use a placeholder implementation
        pass


class SyncTests:
    """Lip sync and timing tests for ManzAI Studio."""
    
    @staticmethod
    def test_lip_sync():
        """Test lip sync accuracy between audio and character animations."""
        # This would typically be implemented using Playwright with custom video analysis
        # For demonstration purposes, we'll use a placeholder implementation
        pass


class ContentTests:
    """Content quality tests for ManzAI Studio."""
    
    @staticmethod
    def test_manzai_quality():
        """Test the quality of generated manzai scripts."""
        # This would typically be implemented using NLP and sentiment analysis
        # For demonstration purposes, we'll use a placeholder implementation
        pass


class WindowTests:
    """Dual window and display tests for ManzAI Studio."""
    
    @staticmethod
    def test_dual_window():
        """Test the dual window functionality."""
        # This would typically be implemented using Playwright
        # For demonstration purposes, we'll use a placeholder implementation
        pass


class ChromaKeyTests:
    """Chroma key and background tests for ManzAI Studio."""
    
    @staticmethod
    def test_chroma_key():
        """Test the chroma key background for streaming."""
        # This would typically be implemented using OpenCV and image analysis
        # For demonstration purposes, we'll use a placeholder implementation
        pass


class AudioDeviceTests:
    """Audio device selection tests for ManzAI Studio."""
    
    @staticmethod
    def test_audio_device_selection():
        """Test audio output device selection."""
        # This would typically be implemented using Playwright
        # For demonstration purposes, we'll use a placeholder implementation
        pass


if __name__ == "__main__":
    runner = TestRunner()
    runner.run()



    """
ManzAI Studio Functional Tests

This module contains automated tests for the ManzAI Studio API endpoints
and core functionality.
"""

import pytest
import requests
import json
import os
from typing import Dict, Any, List, Optional
import time

# Configuration
API_BASE_URL = os.environ.get("API_BASE_URL", "http://localhost:5000/api")
RETRY_ATTEMPTS = 3
RETRY_DELAY = 2  # seconds


class APIClient:
    """Client for interacting with the ManzAI Studio API."""
    
    def __init__(self, base_url: str = API_BASE_URL):
        self.base_url = base_url
    
    def health_check(self) -> Dict[str, Any]:
        """Check the health of the API."""
        response = requests.get(f"{self.base_url}/health")
        response.raise_for_status()
        return response.json()
    
    def generate_manzai(self, topic: str, language: str = "ja", 
                        length: str = "short", tsukkomi_speaker: int = 1,
                        boke_speaker: int = 3) -> Dict[str, Any]:
        """Generate a manzai script."""
        payload = {
            "topic": topic,
            "language": language,
            "length": length,
            "tsukkomiSpeaker": tsukkomi_speaker,
            "bokeSpeaker": boke_speaker
        }
        
        response = requests.post(f"{self.base_url}/generate", json=payload)
        response.raise_for_status()
        return response.json()
    
    def get_audio(self, audio_path: str) -> bytes:
        """Get an audio file."""
        audio_id = audio_path.split('/')[-1]
        response = requests.get(f"{self.base_url}/audio/{audio_id}")
        response.raise_for_status()
        return response.content
    
    def verify_audio_files(self, audio_data: List[Dict[str, str]]) -> bool:
        """Verify that all audio files exist and are accessible."""
        for audio in audio_data:
            try:
                self.get_audio(audio["audio_path"])
            except requests.RequestException:
                return False
        
        return True


@pytest.fixture
def api_client() -> APIClient:
    """Create an API client for testing."""
    return APIClient()


@pytest.fixture
def generated_manzai(api_client: APIClient) -> Dict[str, Any]:
    """Generate a manzai script for testing."""
    for attempt in range(RETRY_ATTEMPTS):
        try:
            return api_client.generate_manzai("テスト漫才")
        except requests.RequestException as e:
            if attempt == RETRY_ATTEMPTS - 1:
                pytest.fail(f"Failed to generate manzai after {RETRY_ATTEMPTS} attempts: {e}")
            time.sleep(RETRY_DELAY)


class TestAPIEndpoints:
    """Test suite for API endpoints."""
    
    def test_health_check(self, api_client: APIClient) -> None:
        """Test that the health check endpoint returns a 200 status."""
        for attempt in range(RETRY_ATTEMPTS):
            try:
                response = api_client.health_check()
                assert response["status"] == "healthy"
                return
            except (requests.RequestException, AssertionError) as e:
                if attempt == RETRY_ATTEMPTS - 1:
                    raise
                time.sleep(RETRY_DELAY)
    
    def test_generate_manzai(self, api_client: APIClient) -> None:
        """Test that the generate endpoint returns a valid script."""
        data = api_client.generate_manzai("テスト漫才")
        
        # Check script structure
        assert "script" in data
        assert isinstance(data["script"], list)
        assert len(data["script"]) > 0
        
        # Check that each line has required fields
        for line in data["script"]:
            assert "role" in line
            assert "text" in line
            assert line["role"] in ["tsukkomi", "boke"]
        
        # Verify audio data
        assert "audio_data" in data
        assert isinstance(data["audio_data"], list)
        assert len(data["audio_data"]) == len(data["script"])
        
        # Verify the pattern of roles (should alternate between tsukkomi and boke)
        roles = [line["role"] for line in data["script"]]
        for i in range(1, len(roles)):
            assert roles[i] != roles[i-1], f"Roles should alternate, but found {roles[i]} after {roles[i-1]}"
    
    def test_audio_generation(self, api_client: APIClient, generated_manzai: Dict[str, Any]) -> None:
        """Test that audio files are generated and accessible."""
        assert api_client.verify_audio_files(generated_manzai["audio_data"])
    
    def test_different_topics(self, api_client: APIClient) -> None:
        """Test that different topics generate different scripts."""
        topics = ["猫", "旅行", "テクノロジー"]
        results = []
        
        for topic in topics:
            data = api_client.generate_manzai(topic)
            results.append(data)
        
        # Check that the scripts are different
        scripts_text = [" ".join([line["text"] for line in result["script"]]) for result in results]
        for i in range(len(scripts_text)):
            for j in range(i + 1, len(scripts_text)):
                # Scripts should be different for different topics
                assert scripts_text[i] != scripts_text[j]
    
    def test_error_handling(self, api_client: APIClient) -> None:
        """Test error handling for invalid inputs."""
        with pytest.raises(requests.HTTPError):
            # Send an empty request
            requests.post(f"{api_client.base_url}/generate", json={}).raise_for_status()


@pytest.mark.parametrize("length", ["short", "medium", "long"])
def test_script_length(api_client: APIClient, length: str) -> None:
    """Test that the length parameter affects the script length."""
    data = api_client.generate_manzai("テスト漫才", length=length)
    
    # Define expected line counts for different lengths
    expected_lengths = {
        "short": (4, 12),   # 4-12 lines
        "medium": (10, 20), # 10-20 lines
        "long": (15, 30)    # 15-30 lines
    }
    
    min_lines, max_lines = expected_lengths[length]
    actual_lines = len(data["script"])
    
    assert min_lines <= actual_lines <= max_lines, \
        f"Script for '{length}' length has {actual_lines} lines, expected between {min_lines} and {max_lines}"


if __name__ == "__main__":
    pytest.main(["-v", __file__])


    """
ManzAI Studio Visual Tests

This module contains automated tests for the ManzAI Studio visual rendering
capabilities, including character display, chroma key background, and UI elements.
"""

import pytest
import numpy as np
import cv2
import io
import time
import base64
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from PIL import Image
from typing import Tuple, List, Dict, Any, Optional


# Configuration
FRONTEND_URL = "http://localhost:5173"
DISPLAY_URL = f"{FRONTEND_URL}/display"
SCREENSHOT_DIR = "test_screenshots"
WAIT_TIMEOUT = 30  # seconds


class ChromaKeyAnalysis:
    """Utility for analyzing chroma key backgrounds in images."""
    
    @staticmethod
    def calculate_green_percentage(image_data: bytes) -> float:
        """Calculate the percentage of green pixels in an image.
        
        Args:
            image_data: Image data as bytes
            
        Returns:
            Percentage of green pixels (0-100)
        """
        # Convert image bytes to PIL Image
        img = Image.open(io.BytesIO(image_data))
        
        # Convert to numpy array and then to BGR format for OpenCV
        img_array = np.array(img)
        img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # Convert to HSV color space
        img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
        
        # Define green color range in HSV
        green_lower = np.array([40, 100, 100])
        green_upper = np.array([80, 255, 255])
        
        # Create a mask of green pixels
        green_mask = cv2.inRange(img_hsv, green_lower, green_upper)
        
        # Calculate percentage of green pixels
        total_pixels = green_mask.shape[0] * green_mask.shape[1]
        green_pixels = np.sum(green_mask > 0)
        green_percentage = (green_pixels / total_pixels) * 100
        
        return green_percentage
    
    @staticmethod
    def detect_character_presence(image_data: bytes) -> Tuple[bool, int]:
        """Detect whether a character is present in the image.
        
        Args:
            image_data: Image data as bytes
            
        Returns:
            Tuple of (character_present, non_green_pixel_count)
        """
        # Convert image bytes to PIL Image
        img = Image.open(io.BytesIO(image_data))
        
        # Convert to numpy array and then to BGR format for OpenCV
        img_array = np.array(img)
        img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # Convert to HSV color space
        img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
        
        # Define green color range in HSV
        green_lower = np.array([40, 100, 100])
        green_upper = np.array([80, 255, 255])
        
        # Create a mask of green pixels
        green_mask = cv2.inRange(img_hsv, green_lower, green_upper)
        
        # Count non-green pixels (potential character pixels)
        non_green_pixels = np.sum(green_mask == 0)
        
        # Consider a character present if there are more than 1000 non-green pixels
        character_present = non_green_pixels > 1000
        
        return character_present, non_green_pixels


class BrowserController:
    """Controls browser interactions for visual testing."""
    
    def __init__(self, headless: bool = True):
        """Initialize browser controller.
        
        Args:
            headless: Whether to run the browser in headless mode
        """
        # Setup Chrome options
        self.options = Options()
        if headless:
            self.options.add_argument('--headless')
        self.options.add_argument('--window-size=1920,1080')
        self.options.add_argument('--no-sandbox')
        self.options.add_argument('--disable-dev-shm-usage')
        
        # Initialize driver
        self.driver = None
    
    def start(self) -> None:
        """Start the browser."""
        self.driver = webdriver.Chrome(options=self.options)
    
    def stop(self) -> None:
        """Stop the browser."""
        if self.driver:
            self.driver.quit()
            self.driver = None
    
    def navigate(self, url: str) -> None:
        """Navigate to a URL.
        
        Args:
            url: URL to navigate to
        """
        self.driver.get(url)
    
    def wait_for_element(self, selector: str, timeout: int = WAIT_TIMEOUT) -> bool:
        """Wait for an element to be present.
        
        Args:
            selector: CSS selector for the element
            timeout: Timeout in seconds
            
        Returns:
            True if the element was found, False otherwise
        """
        try:
            WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, selector))
            )
            return True
        except TimeoutException:
            return False
    
    def take_screenshot(self) -> bytes:
        """Take a screenshot of the current page.
        
        Returns:
            Screenshot data as bytes
        """
        return self.driver.get_screenshot_as_png()