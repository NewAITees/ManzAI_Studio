# ManzAI Studio MVPの開発ステップ計画

以下に、現在の問題点を解決し、MVPを効率的に開発するための具体的なステップを示します。

## フェーズ1: バックエンド開発（2週間）

### ステップ1: Ollama統合の実装
```python
# backend/app/services/ollama_service.py
import requests
from typing import Dict, Any, Optional

class OllamaService:
    def __init__(self, url: str = "http://localhost:11434", model: str = "phi"):
        self.url = url
        self.model = model
        self.api_endpoint = f"{url}/api/generate"
        
    def generate_manzai(self, topic: str, length: str = "medium") -> Optional[Dict[str, Any]]:
        """漫才スクリプトを生成する"""
        prompt = self._create_manzai_prompt(topic, length)
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        
        try:
            response = requests.post(self.api_endpoint, json=payload)
            response.raise_for_status()
            result = response.json()
            
            # レスポンスから漫才スクリプトを抽出して整形
            script = self._parse_manzai_script(result["response"])
            return script
        except requests.RequestException as e:
            print(f"Ollama API Error: {e}")
            return None
            
    def _create_manzai_prompt(self, topic: str, length: str) -> str:
        """漫才生成用のプロンプトを作成"""
        # 長さに応じたガイドを設定
        length_guide = {
            "short": "30秒程度（約150字）",
            "medium": "1分程度（約300字）",
            "long": "2分程度（約600字）"
        }
        
        prompt = f"""
        あなたは日本の伝統的な漫才を生成するアシスタントです。
        以下のフォーマットで、「{topic}」についての{length_guide[length]}の漫才を作成してください。
        
        形式:
        ツッコミ(A): [セリフ]
        ボケ(B): [セリフ]
        
        漫才の特徴:
        - ボケとツッコミの明確な役割分担
        - テンポの良い掛け合い
        - 起承転結のある構成
        - オチで締める
        
        漫才を開始してください。
        """
        return prompt
        
    def _parse_manzai_script(self, raw_text: str) -> Dict[str, Any]:
        """生成されたテキストから漫才スクリプトを抽出"""
        lines = raw_text.strip().split('\n')
        script = []
        
        for line in lines:
            line = line.strip()
            if line.startswith(('ツッコミ(A):', 'ボケ(B):')):
                parts = line.split(':', 1)
                role = "tsukkomi" if "ツッコミ" in parts[0] else "boke"
                text = parts[1].strip() if len(parts) > 1 else ""
                
                if text:
                    script.append({"role": role, "text": text})
        
        return {"script": script}
```

### ステップ2: VoiceVox統合の実装
```python
# backend/app/services/voicevox_service.py
import os
import requests
import json
import uuid
from typing import Dict, Any, List, Optional, Tuple
import base64

class VoiceVoxService:
    def __init__(self, url: str = "http://localhost:50021"):
        self.url = url
        
    def generate_voice(self, text: str, speaker_id: int = 1) -> Tuple[Optional[bytes], Optional[Dict]]:
        """テキストから音声を生成"""
        try:
            # 1. 音声合成用パラメータを取得
            params_response = requests.post(
                f"{self.url}/audio_query?text={text}&speaker={speaker_id}"
            )
            params_response.raise_for_status()
            params = params_response.json()
            
            # 2. 音声を合成
            synthesis_response = requests.post(
                f"{self.url}/synthesis?speaker={speaker_id}",
                json=params
            )
            synthesis_response.raise_for_status()
            
            # 3. モーラ情報を取得 (リップシンク用)
            accent_response = requests.post(
                f"{self.url}/accent_phrases?text={text}&speaker={speaker_id}"
            )
            accent_response.raise_for_status()
            accent_data = accent_response.json()
            
            return synthesis_response.content, accent_data
        except requests.RequestException as e:
            print(f"VoiceVox API Error: {e}")
            return None, None
            
    def generate_manzai_voices(self, script: List[Dict[str, str]]) -> List[Dict[str, Any]]:
        """漫才スクリプト全体の音声を生成"""
        audio_data = []
        
        # キャラクター設定（役割ごとに異なる声）
        speakers = {
            "tsukkomi": 1,  # ツッコミ役 (例: 四国めたん)
            "boke": 3       # ボケ役 (例: ずんだもん)
        }
        
        for i, line in enumerate(script):
            role = line["role"]
            text = line["text"]
            speaker_id = speakers.get(role, 1)
            
            # 音声とアクセント情報を生成
            audio, accent = self.generate_voice(text, speaker_id)
            
            if audio:
                # 一意のファイル名を生成
                filename = f"voice_{role}_{i}_{uuid.uuid4().hex[:8]}.wav"
                filepath = os.path.join("static", "audio", filename)
                
                # ディレクトリが存在するか確認
                os.makedirs(os.path.dirname(filepath), exist_ok=True)
                
                # 音声ファイルを保存
                with open(filepath, "wb") as f:
                    f.write(audio)
                
                # 結果を追加
                audio_data.append({
                    "role": role,
                    "text": text,
                    "audio_path": filepath,
                    "accent_data": accent,
                    "speaker_id": speaker_id
                })
        
        return audio_data
```

### ステップ3: APIエンドポイントの更新
```python
# backend/app/routes/api.py
from flask import Blueprint, jsonify, request, current_app, send_from_directory
from typing import Dict, Any, List, Union

from backend.app.services.ollama_service import OllamaService
from backend.app.services.voicevox_service import VoiceVoxService

bp = Blueprint("api", __name__, url_prefix="/api")
ollama_service = None
voicevox_service = None

@bp.before_app_first_request
def setup_services():
    """アプリ初回リクエスト時にサービスを初期化"""
    global ollama_service, voicevox_service
    ollama_service = OllamaService(
        url=current_app.config["OLLAMA_URL"],
        model=current_app.config["OLLAMA_MODEL"]
    )
    voicevox_service = VoiceVoxService(
        url=current_app.config["VOICEVOX_URL"]
    )

@bp.route("/health", methods=["GET"])
def health_check() -> Dict[str, str]:
    """ヘルスチェックエンドポイント"""
    return jsonify({"status": "healthy"})

@bp.route("/generate", methods=["POST"])
def generate_manzai() -> Union[Dict[str, Any], tuple]:
    """漫才を生成するエンドポイント"""
    data = request.get_json()
    if not data or "topic" not in data:
        return jsonify({"error": "No topic provided"}), 400

    topic = data["topic"]
    length = data.get("length", "medium")
    
    # 1. Ollamaを使って漫才スクリプトを生成
    script_result = ollama_service.generate_manzai(topic, length)
    if not script_result:
        return jsonify({"error": "Failed to generate script"}), 500
    
    # 2. VoiceVoxを使って音声を生成
    audio_data = voicevox_service.generate_manzai_voices(script_result["script"])
    if not audio_data:
        return jsonify({"error": "Failed to generate audio"}), 500
    
    # 3. 結果を返す
    result = {
        "topic": topic,
        "script": script_result["script"],
        "audio_data": audio_data
    }
    
    return jsonify(result)

@bp.route("/audio/<path:filename>", methods=["GET"])
def get_audio(filename: str):
    """音声ファイルを提供するエンドポイント"""
    return send_from_directory("static/audio", filename)
```

## フェーズ2: フロントエンド開発（2週間）

### ステップ1: フロントエンドプロジェクト構築
```bash
# フロントエンドプロジェクトのセットアップ
cd frontend
npm init vite@latest . -- --template react
npm install

# 必要なライブラリのインストール
npm install axios bootstrap react-bootstrap
```

### ステップ2: Live2D統合コンポーネントの作成
```javascript
// frontend/src/components/Live2DCharacter.jsx
import React, { useEffect, useRef } from 'react';

const Live2DCharacter = ({ characterId, mouthOpenValue = 0, expression = 'neutral' }) => {
  const canvasRef = useRef(null);
  const live2dRef = useRef(null);

  useEffect(() => {
    // Live2D SDKをロード
    const script = document.createElement('script');
    script.src = '/live2d/live2dcubismcore.min.js';
    script.async = true;
    document.body.appendChild(script);

    script.onload = () => {
      const frameworkScript = document.createElement('script');
      frameworkScript.src = '/live2d/live2d.min.js';
      frameworkScript.async = true;
      document.body.appendChild(frameworkScript);

      frameworkScript.onload = () => {
        initLive2D();
      };
    };

    return () => {
      document.body.removeChild(script);
      if (live2dRef.current) {
        // Live2Dをクリーンアップ
        live2dRef.current.release();
      }
    };
  }, [characterId]);

  // Live2Dの初期化
  const initLive2D = () => {
    if (!canvasRef.current) return;

    // Live2Dモデルのロード
    const modelPath = `/live2d/characters/${characterId}/model.json`;
    
    live2dRef.current = new Live2DCubismCore.Model();
    live2dRef.current.loadModel(modelPath);
    live2dRef.current.startMotion('Idle');
  };

  // 口の開閉を制御
  useEffect(() => {
    if (live2dRef.current) {
      live2dRef.current.setParamFloat('ParamMouthOpenY', mouthOpenValue);
    }
  }, [mouthOpenValue]);

  // 表情を制御
  useEffect(() => {
    if (!live2dRef.current) return;
    
    // 表情に応じてパラメータを設定
    switch(expression) {
      case 'happy':
        live2dRef.current.setParamFloat('ParamEyeLSmile', 1);
        live2dRef.current.setParamFloat('ParamEyeRSmile', 1);
        break;
      case 'sad':
        live2dRef.current.setParamFloat('ParamBrowLY', -1);
        live2dRef.current.setParamFloat('ParamBrowRY', -1);
        break;
      default:
        // ニュートラル表情
        live2dRef.current.setParamFloat('ParamEyeLSmile', 0);
        live2dRef.current.setParamFloat('ParamEyeRSmile', 0);
        live2dRef.current.setParamFloat('ParamBrowLY', 0);
        live2dRef.current.setParamFloat('ParamBrowRY', 0);
    }
  }, [expression]);

  return (
    <canvas 
      ref={canvasRef} 
      width="600" 
      height="600" 
      style={{ 
        backgroundColor: 'transparent',
        width: '100%',
        height: '100%'
      }}
    />
  );
};

export default Live2DCharacter;
```

### ステップ3: メインアプリケーションコンポーネント
```javascript
// frontend/src/App.jsx
import React, { useState } from 'react';
import axios from 'axios';
import { Container, Row, Col, Form, Button, Alert } from 'react-bootstrap';
import Live2DCharacter from './components/Live2DCharacter';
import 'bootstrap/dist/css/bootstrap.min.css';

const App = () => {
  const [topic, setTopic] = useState('');
  const [length, setLength] = useState('medium');
  const [isGenerating, setIsGenerating] = useState(false);
  const [error, setError] = useState('');
  const [manzaiData, setManzaiData] = useState(null);
  const [currentLineIndex, setCurrentLineIndex] = useState(-1);
  const [isPlaying, setIsPlaying] = useState(false);
  const [mouthOpenValue, setMouthOpenValue] = useState(0);
  const [characterExpression, setCharacterExpression] = useState('neutral');
  
  // 音声再生用オーディオ要素の参照
  const audioRef = React.useRef(new Audio());
  
  // 漫才を生成
  const generateManzai = async () => {
    if (!topic) {
      setError('トピックを入力してください');
      return;
    }
    
    setError('');
    setIsGenerating(true);
    
    try {
      const response = await axios.post('/api/generate', {
        topic,
        length
      });
      
      setManzaiData(response.data);
      setIsGenerating(false);
    } catch (err) {
      console.error('Error generating manzai:', err);
      setError('漫才の生成に失敗しました。もう一度お試しください。');
      setIsGenerating(false);
    }
  };
  
  // 漫才を再生
  const playManzai = () => {
    if (!manzaiData || manzaiData.audio_data.length === 0) return;
    
    setIsPlaying(true);
    setCurrentLineIndex(0);
    playCurrentLine(0);
  };
  
  // 現在の行を再生
  const playCurrentLine = (index) => {
    if (index >= manzaiData.audio_data.length) {
      setIsPlaying(false);
      setCurrentLineIndex(-1);
      setMouthOpenValue(0);
      setCharacterExpression('neutral');
      return;
    }
    
    const line = manzaiData.audio_data[index];
    const audioPath = `/api/audio/${line.audio_path.split('/').pop()}`;
    
    // 役割に応じた表情を設定
    const expression = line.role === 'boke' ? 'happy' : 'neutral';
    setCharacterExpression(expression);
    
    // オーディオを設定して再生
    audioRef.current.src = audioPath;
    audioRef.current.onplay = () => setMouthOpenValue(1);
    audioRef.current.onended = () => {
      setMouthOpenValue(0);
      // 次の行へ
      setTimeout(() => {
        playCurrentLine(index + 1);
        setCurrentLineIndex(index + 1);
      }, 500); // 500msの間隔
    };
    
    audioRef.current.play().catch(err => {
      console.error('Error playing audio:', err);
    });
  };
  
  // 漫才を停止
  const stopManzai = () => {
    audioRef.current.pause();
    audioRef.current.currentTime = 0;
    setIsPlaying(false);
    setCurrentLineIndex(-1);
    setMouthOpenValue(0);
    setCharacterExpression('neutral');
  };
  
  return (
    <Container className="mt-5">
      <h1 className="text-center mb-4">ManzAI Studio</h1>
      
      <Row className="mb-4">
        <Col md={6}>
          <Form>
            <Form.Group className="mb-3">
              <Form.Label>トピック</Form.Label>
              <Form.Control 
                type="text" 
                value={topic} 
                onChange={(e) => setTopic(e.target.value)}
                placeholder="例: 猫、旅行、AI..."
                disabled={isGenerating || isPlaying}
              />
            </Form.Group>
            
            <Form.Group className="mb-3">
              <Form.Label>長さ</Form.Label>
              <Form.Select 
                value={length} 
                onChange={(e) => setLength(e.target.value)}
                disabled={isGenerating || isPlaying}
              >
                <option value="short">短め (30秒程度)</option>
                <option value="medium">普通 (1分程度)</option>
                <option value="long">長め (2分程度)</option>
              </Form.Select>
            </Form.Group>
            
            <Button 
              variant="primary" 
              onClick={generateManzai}
              disabled={isGenerating || isPlaying || !topic}
              className="me-2"
            >
              {isGenerating ? '生成中...' : '漫才を生成'}
            </Button>
            
            {manzaiData && (
              <Button 
                variant={isPlaying ? "danger" : "success"} 
                onClick={isPlaying ? stopManzai : playManzai}
                disabled={isGenerating}
              >
                {isPlaying ? '停止' : '再生'}
              </Button>
            )}
          </Form>
          
          {error && <Alert variant="danger" className="mt-3">{error}</Alert>}
        </Col>
        
        <Col md={6}>
          <div 
            style={{ 
              width: '100%', 
              height: '400px', 
              border: '1px solid #ddd',
              borderRadius: '4px',
              overflow: 'hidden',
              backgroundColor: '#00FF00' // クロマキー用の緑背景
            }}
          >
            <Live2DCharacter 
              characterId={currentLineIndex >= 0 && manzaiData ? 
                (manzaiData.audio_data[currentLineIndex].role === 'tsukkomi' ? 'character1' : 'character2') : 
                'character1'
              }
              mouthOpenValue={mouthOpenValue}
              expression={characterExpression}
            />
          </div>
        </Col>
      </Row>
      
      {manzaiData && (
        <Row>
          <Col>
            <h3>生成された漫才</h3>
            <div className="border p-3 rounded">
              {manzaiData.script.map((line, i) => (
                <div 
                  key={i} 
                  className={`mb-2 ${currentLineIndex === i ? 'bg-light' : ''}`}
                >
                  <strong>{line.role === 'tsukkomi' ? 'ツッコミ: ' : 'ボケ: '}</strong>
                  {line.text}
                </div>
              ))}
            </div>
          </Col>
        </Row>
      )}
    </Container>
  );
};

export default App;
```

## フェーズ3: コンポーネント統合と設定（1週間）

### ステップ1: 設定ファイルの更新
```python
# backend/app/config.py に以下の設定を追加
@dataclass
class Config:
    """Base configuration."""
    TESTING: bool = False
    VOICEVOX_URL: str = os.getenv("VOICEVOX_URL", "http://localhost:50021")
    OLLAMA_URL: str = os.getenv("OLLAMA_URL", "http://localhost:11434")
    OLLAMA_MODEL: str = os.getenv("OLLAMA_MODEL", "phi")
    AUDIO_FOLDER: str = os.path.join("static", "audio")
    ALLOW_ORIGIN: str = os.getenv("ALLOW_ORIGIN", "http://localhost:5173")  # Viteのデフォルトポート
```

### ステップ2: Live2Dモデルの配置
```bash
# Live2Dモデル用のディレクトリを作成
mkdir -p frontend/public/live2d/characters/character1
mkdir -p frontend/public/live2d/characters/character2

# Live2D Cubism SDKをダウンロードして配置
# 注: 実際にはLive2D Cubism SDKのライセンスを確認し、適切にダウンロードする必要があります
curl -o frontend/public/live2d/live2dcubismcore.min.js https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js
```

### ステップ3: 起動スクリプトの作成
```python
# run.py
import os
import subprocess
import threading
import time
from flask import Flask
from backend.app import create_app

def check_ollama_running():
    """Ollamaが実行中かチェック"""
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags")
        return response.status_code == 200
    except:
        return False

def check_voicevox_running():
    """VoiceVoxが実行中かチェック"""
    try:
        import requests
        response = requests.get("http://localhost:50021/version")
        return response.status_code == 200
    except:
        return False

def start_ollama():
    """Ollamaを起動"""
    if not check_ollama_running():
        print("Starting Ollama...")
        subprocess.Popen(["ollama", "serve"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # phiモデルがダウンロード済みかチェック
        time.sleep(2)  # サーバー起動を待つ
        try:
            import requests
            response = requests.get("http://localhost:11434/api/tags")
            models = response.json().get("models", [])
            if not any(model.get("name") == "phi" for model in models):
                print("Downloading phi model (this may take a while)...")
                subprocess.run(["ollama", "pull", "phi"])
        except Exception as e:
            print(f"Error checking Ollama models: {e}")

def start_voicevox():
    """VoiceVoxを起動"""
    if not check_voicevox_running():
        print("Starting VoiceVox...")
        subprocess.Popen(["voicevox", "--use_gpu", "false"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)

def start_frontend():
    """フロントエンド開発サーバーを起動"""
    os.chdir("frontend")
    subprocess.Popen(["npm", "run", "dev"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    os.chdir("..")

if __name__ == "__main__":
    # 依存サービスの起動
    ollama_thread = threading.Thread(target=start_ollama)
    voicevox_thread = threading.Thread(target=start_voicevox)
    frontend_thread = threading.Thread(target=start_frontend)
    
    ollama_thread.start()
    voicevox_thread.start()
    frontend_thread.start()
    
    # サービスの起動を待つ
    time.sleep(5)
    
    # Flaskアプリケーション起動
    app = create_app()
    app.run(debug=True, port=5000)
```

## フェーズ4: テストと最適化（1週間）

### ステップ1: テストケースの追加
```python
# backend/tests/test_services.py
import pytest
from unittest.mock import patch, MagicMock
from backend.app.services.ollama_service import OllamaService
from backend.app.services.voicevox_service import VoiceVoxService

class TestOllamaService:
    @patch('backend.app.services.ollama_service.requests.post')
    def test_generate_manzai_success(self, mock_post):
        # モックのレスポンスを設定
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "response": """
            ツッコミ(A): こんにちは！今日のお題は「猫」だって。
            ボケ(B): 猫って可愛いよね〜。うちの猫なんか、私が帰ると必ず玄関に迎えに来てくれるの。
            ツッコミ(A): へー、忠実な猫だね。
            """
        }
        mock_post.return_value = mock_response
        
        # サービスをテスト
        service = OllamaService(url="http://test", model="test-model")
        result = service.generate_manzai("猫")
        
        # 結果を検証
        assert result is not None
        assert "script" in result
        assert len(result["script"]) == 3
        assert result["script"][0]["role"] == "tsukkomi"
        assert result["script"][1]["role"] == "boke"
```

### ステップ2: パフォーマンス最適化
```python
# backend/app/services/ollama_service.py に追加

def generate_manzai_cached(self, topic: str, length: str = "medium") -> Optional[Dict[str, Any]]:
    """キャッシュを活用した漫才スクリプト生成"""
    import hashlib
    import json
    import os
    from datetime import datetime, timedelta
    
    # キャッシュキーを生成
    cache_key = hashlib.md5(f"{topic}_{length}_{self.model}".encode()).hexdigest()
    cache_dir = os.path.join("cache", "manzai")
    cache_file = os.path.join(cache_dir, f"{cache_key}.json")
    
    # キャッシュディレクトリを作成
    os.makedirs(cache_dir, exist_ok=True)
    
    # キャッシュが存在し、24時間以内であれば使用
    if os.path.exists(cache_file):
        file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
        if datetime.now() - file_time < timedelta(hours=24):
            try:
                with open(cache_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                pass  # キャッシュが壊れている場合は生成する
    
    # キャッシュがない場合は新規生成
    result = self.generate_manzai(topic, length)
    
    # 結果をキャッシュ
    if result:
        with open(cache_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    
    return result
```

## まとめ: 実装計画

1. **バックエンド開発** (2週間)
   - Ollama統合サービスの実装
   - VoiceVox統合サービスの実装
   - APIエンドポイントの更新

2. **フロントエンド開発** (2週間)
   - フロントエンドプロジェクト構築
   - Live2Dキャラクターコンポーネント作成
   - メインアプリケーション画面実装

3. **コンポーネント統合** (1週間)
   - 設定ファイルの更新
   - Live2Dモデルの配置・設定
   - 統合起動スクリプトの作成

4. **テストと最適化** (1週間)
   - テストケースの追加・実行
   - パフォーマンス最適化
   - デバッグと問題解決

この計画に従えば、約6週間でMVP版のManzAI Studioを開発できます。各フェーズは並行して進めることも可能で、早期にプロトタイプを作成してフィードバックを得ることができます。



# ManzAI Studio - 追加要件対応計画

ご指摘いただいた2つの追加要件について、対応計画を示します：

1. **音声出力デバイス選択機能**
2. **クロマキー利用時のUI最適化**

これらの重要な配慮点を追加した修正計画を示します。

## フェーズ1: 音声出力デバイス選択機能（3日間）

### ステップ1: オーディオデバイス検出と選択機能の実装

```javascript
// frontend/src/services/audio.js (新規ファイル)
/**
 * オーディオ出力デバイスを取得する
 */
export const getAudioOutputDevices = async () => {
  try {
    // ブラウザがMedia Devices APIをサポートしているか確認
    if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
      console.warn("このブラウザはデバイス選択をサポートしていません");
      return [];
    }
    
    // デバイス一覧を取得
    const devices = await navigator.mediaDevices.enumerateDevices();
    
    // 出力デバイスのみをフィルタリング
    return devices.filter(device => device.kind === 'audiooutput');
  } catch (error) {
    console.error("オーディオデバイスの取得に失敗しました:", error);
    return [];
  }
};

/**
 * 指定されたオーディオ要素に出力デバイスを設定する
 */
export const setAudioOutputDevice = async (audioElement, deviceId) => {
  try {
    // オーディオ要素とブラウザがsinkIdをサポートしているか確認
    if (audioElement && typeof audioElement.setSinkId === 'function') {
      await audioElement.setSinkId(deviceId);
      return true;
    } else {
      console.warn("このブラウザは出力デバイスの変更をサポートしていません");
      return false;
    }
  } catch (error) {
    console.error("出力デバイスの設定に失敗しました:", error);
    return false;
  }
};
```

## フェーズ2: クロマキー対応UI設計（5日間）

### ステップ1: ウィンドウ分離モードの実装

```javascript
// frontend/src/components/ControlPanel.jsx (新規ファイル)
import React, { useState, useEffect } from 'react';
import { Button, Form, Row, Col } from 'react-bootstrap';

/**
 * 分離可能な制御パネル
 */
const ControlPanel = ({
  onGenerateManzai,
  onPlayManzai,
  onStopManzai,
  isPlaying,
  isGenerating,
  topic,
  setTopic,
  language,
  setLanguage,
  // その他の必要なプロパティ
}) => {
  return (
    <div className="control-panel">
      <h3>{language === 'ja' ? '制御パネル' : 'Control Panel'}</h3>
      <Form>
        {/* 言語選択、トピック入力、話者選択などのUI */}
        {/* ...既存のUI要素... */}
        
        <Button 
          variant="primary" 
          onClick={onGenerateManzai}
          disabled={isGenerating || isPlaying || !topic}
          className="me-2"
        >
          {isGenerating ? 
            (language === 'ja' ? '生成中...' : 'Generating...') : 
            (language === 'ja' ? '漫才を生成' : 'Generate Manzai')}
        </Button>
        
        <Button 
          variant={isPlaying ? "danger" : "success"} 
          onClick={isPlaying ? onStopManzai : onPlayManzai}
          disabled={isGenerating}
        >
          {isPlaying ? 
            (language === 'ja' ? '停止' : 'Stop') : 
            (language === 'ja' ? '再生' : 'Play')}
        </Button>
      </Form>
    </div>
  );
};

export default ControlPanel;
```

### ステップ2: キャラクター表示専用モードの実装

```javascript
// frontend/src/components/CharacterDisplayMode.jsx (新規ファイル)
import React, { useEffect } from 'react';
import CharacterStage from './CharacterStage';

/**
 * キャラクター表示専用モード（クロマキー用）
 */
const CharacterDisplayMode = ({
  characters,
  currentSpeaker,
  mouthOpenValues,
  characterPositions,
  backgroundColor = '#00FF00' // デフォルトのクロマキー緑
}) => {
  // フルスクリーン表示用のキーボードショートカット
  useEffect(() => {
    const handleKeyDown = (e) => {
      // F11キーでフルスクリーン切替
      if (e.key === 'F11') {
        e.preventDefault();
        if (!document.fullscreenElement) {
          document.documentElement.requestFullscreen();
        } else {
          document.exitFullscreen();
        }
      }
      
      // ESCキーでクロマキーモード終了
      if (e.key === 'Escape' && document.fullscreenElement) {
        document.exitFullscreen();
      }
    };
    
    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, []);
  
  return (
    <div 
      className="character-display-mode"
      style={{ 
        width: '100vw', 
        height: '100vh', 
        backgroundColor: backgroundColor,
        overflow: 'hidden',
        position: 'fixed',
        top: 0,
        left: 0
      }}
    >
      <CharacterStage 
        characters={characters}
        currentSpeaker={currentSpeaker}
        mouthOpenValues={mouthOpenValues}
        positions={characterPositions}
        displayOnly={true} // ドラッグ無効化
      />
    </div>
  );
};

export default CharacterDisplayMode;
```

### ステップ3: デュアルウィンドウモードの実装

```javascript
// frontend/src/DualWindowManager.js (新規ファイル)
/**
 * 新しいウィンドウを開く
 */
export const openCharacterWindow = (url, title) => {
  // ウィンドウのサイズと位置を設定
  const width = 800;
  const height = 600;
  const left = window.screen.width - width;
  const top = 0;
  
  // 新しいウィンドウを開く
  const newWindow = window.open(
    url,
    title,
    `width=${width},height=${height},left=${left},top=${top}`
  );
  
  if (newWindow) {
    // フォーカスを新しいウィンドウに設定
    newWindow.focus();
    return newWindow;
  }
  
  return null;
};

// main.jsx に新しいルートを追加
import React from 'react';
import ReactDOM from 'react-dom/client';
import { BrowserRouter, Routes, Route } from 'react-router-dom';
import App from './App';
import CharacterDisplayMode from './components/CharacterDisplayMode';
import './index.css';

ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <BrowserRouter>
      <Routes>
        <Route path="/" element={<App />} />
        <Route path="/display" element={<CharacterDisplayMode />} />
      </Routes>
    </BrowserRouter>
  </React.StrictMode>,
);
```

## フェーズ3: アプリケーションUIの最適化（4日間）

### ステップ1: App.jsx の修正とキーボードショートカットの実装

```javascript
// App.jsx に追加する修正
import React, { useState, useEffect, useRef } from 'react';
import { Container, Row, Col, Form, Button, Alert, Tabs, Tab } from 'react-bootstrap';
import CharacterStage from './components/CharacterStage';
import ControlPanel from './components/ControlPanel';
import { getAudioOutputDevices, setAudioOutputDevice } from './services/audio';
import { openCharacterWindow } from './DualWindowManager';
import { saveSettings, loadSettings } from './services/storage';
import 'bootstrap/dist/css/bootstrap.min.css';

const App = () => {
  // 既存のstate変数
  
  // 新しいstate変数
  const [audioDevices, setAudioDevices] = useState([]);
  const [selectedAudioDevice, setSelectedAudioDevice] = useState('default');
  const [isDisplayWindowOpen, setIsDisplayWindowOpen] = useState(false);
  const [displayWindow, setDisplayWindow] = useState(null);
  const [showControls, setShowControls] = useState(true);
  
  // 音声再生用オーディオ要素の参照
  const audioRef = useRef(new Audio());
  
  // 利用可能なオーディオデバイスを取得
  useEffect(() => {
    const fetchAudioDevices = async () => {
      const devices = await getAudioOutputDevices();
      setAudioDevices(devices);
      
      // 保存されている設定から選択デバイスを復元
      const settings = loadSettings();
      if (settings && settings.audioDevice) {
        setSelectedAudioDevice(settings.audioDevice);
      }
    };
    
    fetchAudioDevices();
  }, []);
  
  // オーディオデバイスが変更されたときの処理
  useEffect(() => {
    if (audioRef.current) {
      setAudioOutputDevice(audioRef.current, selectedAudioDevice);
      
      // 設定を保存
      const settings = loadSettings() || {};
      settings.audioDevice = selectedAudioDevice;
      saveSettings(settings);
    }
  }, [selectedAudioDevice]);
  
  // キーボードショートカットの設定
  useEffect(() => {
    const handleKeyDown = (e) => {
      // スペースキーで再生/停止トグル
      if (e.code === 'Space' && !isGenerating && manzaiData) {
        e.preventDefault();
        if (isPlaying) {
          stopManzai();
        } else {
          playManzai();
        }
      }
      
      // Ctrl+N で新しい漫才生成
      if (e.ctrlKey && e.code === 'KeyN' && !isGenerating && !isPlaying) {
        e.preventDefault();
        generateManzai();
      }
      
      // Ctrl+D でディスプレイモードトグル
      if (e.ctrlKey && e.code === 'KeyD') {
        e.preventDefault();
        toggleDisplayWindow();
      }
      
      // Ctrl+H でコントロール表示/非表示トグル
      if (e.ctrlKey && e.code === 'KeyH') {
        e.preventDefault();
        setShowControls(!showControls);
      }
    };
    
    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [isPlaying, isGenerating, manzaiData, showControls]);
  
  // ディスプレイウィンドウのトグル
  const toggleDisplayWindow = () => {
    if (!isDisplayWindowOpen) {
      // 新しいウィンドウを開く
      const newWindow = openCharacterWindow('/display', 'ManzAI Character Display');
      
      if (newWindow) {
        setDisplayWindow(newWindow);
        setIsDisplayWindowOpen(true);
        
        // ウィンドウが閉じられたときのハンドラ
        newWindow.onbeforeunload = () => {
          setIsDisplayWindowOpen(false);
          setDisplayWindow(null);
        };
      }
    } else if (displayWindow) {
      // 既存のウィンドウを閉じる
      displayWindow.close();
      setIsDisplayWindowOpen(false);
      setDisplayWindow(null);
    }
  };
  
  // UI表示
  return (
    <Container className="mt-5" fluid={!showControls}>
      <div className={showControls ? '' : 'd-none'}>
        <h1 className="text-center mb-4">ManzAI Studio</h1>
        
        <div className="mb-3 d-flex justify-content-end">
          <Button 
            variant="outline-secondary" 
            onClick={toggleDisplayWindow}
            className="me-2"
          >
            {isDisplayWindowOpen ? '表示ウィンドウを閉じる' : '表示ウィンドウを開く'}
          </Button>
          <Button 
            variant="outline-secondary" 
            onClick={() => setShowControls(false)}
          >
            コントロールを隠す (Ctrl+H)
          </Button>
        </div>
        
        <Tabs defaultActiveKey="generator" className="mb-3">
          <Tab eventKey="generator" title="漫才生成">
            <Row className="mb-4">
              <Col md={6}>
                <Form>
                  {/* 既存のフォーム要素 */}
                  
                  {/* 音声出力デバイス選択を追加 */}
                  <Form.Group className="mb-3">
                    <Form.Label>音声出力デバイス</Form.Label>
                    <Form.Select 
                      value={selectedAudioDevice}
                      onChange={(e) => setSelectedAudioDevice(e.target.value)}
                    >
                      <option value="default">デフォルトデバイス</option>
                      {audioDevices.map(device => (
                        <option key={device.deviceId} value={device.deviceId}>
                          {device.label || `出力デバイス (${device.deviceId})`}
                        </option>
                      ))}
                    </Form.Select>
                  </Form.Group>
                  
                  {/* その他の既存フォーム要素 */}
                </Form>
              </Col>
              
              <Col md={6}>
                {/* キャラクターステージ */}
                <CharacterStage 
                  characters={characters}
                  currentSpeaker={currentLineIndex >= 0 && manzaiData ? manzaiData.script[currentLineIndex].role : null}
                  mouthOpenValues={mouthOpenValues}
                  onPositionChange={handleCharacterPositionChange}
                />
              </Col>
            </Row>
          </Tab>
          
          <Tab eventKey="settings" title="設定">
            {/* 既存の設定タブ内容 */}
            
            {/* クロマキー設定セクションを追加 */}
            <Row>
              <Col md={6}>
                <h3>クロマキー設定</h3>
                <p>配信ソフトでクロマキー合成するための設定です。</p>
                
                <Form.Group className="mb-3">
                  <Form.Label>背景色</Form.Label>
                  <Form.Control 
                    type="color" 
                    value="#00FF00" // デフォルトのクロマキー緑
                    onChange={(e) => {
                      // 背景色変更処理
                    }}
                  />
                </Form.Group>
                
                <Form.Check 
                  type="checkbox"
                  id="enable-display-only-mode"
                  label="キャラクター表示のみモード (UI非表示)"
                  checked={!showControls}
                  onChange={(e) => setShowControls(!e.target.checked)}
                  className="mb-3"
                />
                
                <Button 
                  variant="primary" 
                  onClick={toggleDisplayWindow}
                  className="mb-3"
                >
                  {isDisplayWindowOpen ? '表示ウィンドウを閉じる' : '表示ウィンドウを開く'}
                </Button>
                
                <div className="mb-3">
                  <h4>キーボードショートカット</h4>
                  <ul>
                    <li><strong>スペース</strong>: 再生/停止</li>
                    <li><strong>Ctrl+N</strong>: 新規生成</li>
                    <li><strong>Ctrl+D</strong>: 表示ウィンドウ切替</li>
                    <li><strong>Ctrl+H</strong>: コントロール表示/非表示</li>
                    <li><strong>F11</strong>: フルスクリーン切替 (表示ウィンドウで)</li>
                  </ul>
                </div>
              </Col>
            </Row>
          </Tab>
        </Tabs>
        
        {/* 生成された漫才スクリプト表示 */}
        {manzaiData && (
          <Row className="mt-4">
            <Col>
              <h3>生成された漫才</h3>
              <div className="border p-3 rounded">
                {/* 既存のスクリプト表示 */}
              </div>
            </Col>
          </Row>
        )}
      </div>
      
      {/* コントロール非表示モードのときに表示される最小限UI */}
      {!showControls && (
        <div className="minimal-controls position-fixed top-0 end-0 p-2 bg-dark bg-opacity-50 text-white rounded-bottom-start">
          <Button 
            variant="outline-light" 
            size="sm"
            onClick={() => setShowControls(true)}
          >
            コントロール表示 (Ctrl+H)
          </Button>
        </div>
      )}
      
      {/* キャラクター表示（コントロール非表示モードのとき） */}
      {!showControls && (
        <div className="full-screen-display">
          <CharacterStage 
            characters={characters}
            currentSpeaker={currentLineIndex >= 0 && manzaiData ? manzaiData.script[currentLineIndex].role : null}
            mouthOpenValues={mouthOpenValues}
            onPositionChange={handleCharacterPositionChange}
          />
        </div>
      )}
    </Container>
  );
};

export default App;
```

## フェーズ4: システム統合と最終テスト（3日間）

### ステップ1: index.html の修正

```html
<!-- frontend/index.html -->
<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ManzAI Studio</title>
  <style>
    /* 表示モード用のスタイル */
    body.display-mode {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: #00FF00; /* デフォルトのクロマキー緑 */
    }
    
    /* UI非表示モード用のスタイル */
    .controls-hidden {
      overflow: hidden;
    }
    
    .controls-hidden .container-fluid {
      padding: 0;
      margin: 0;
      max-width: 100%;
    }
    
    .minimal-controls {
      z-index: 1000;
      opacity: 0.2;
      transition: opacity 0.3s;
    }
    
    .minimal-controls:hover {
      opacity: 1;
    }
    
    .full-screen-display {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background-color: #00FF00; /* クロマキー用背景 */
      z-index: 0;
    }
  </style>
</head>
<body>
  <div id="root"></div>
  <script>
    // URLパスに基づいてBodyクラスを設定
    if (window.location.pathname === '/display') {
      document.body.classList.add('display-mode');
    }
  </script>
  <script type="module" src="/src/main.jsx"></script>
</body>
</html>
```

### ステップ2: クロスウィンドウ通信の実装

```javascript
// frontend/src/services/windowCommunication.js (新規ファイル)
/**
 * メインウィンドウとディスプレイウィンドウ間の通信を処理する
 */
export class WindowCommunicator {
  constructor() {
    this.displayWindow = null;
    this.isMainWindow = window.opener === null;
    this.messageHandlers = {};
    
    // メッセージリスナーを設定
    window.addEventListener('message', this.handleMessage.bind(this));
  }
  
  /**
   * ディスプレイウィンドウを設定
   */
  setDisplayWindow(window) {
    this.displayWindow = window;
  }
  
  /**
   * メッセージハンドラーを登録
   */
  registerHandler(type, handler) {
    this.messageHandlers[type] = handler;
  }
  
  /**
   * メッセージを送信
   */
  sendMessage(type, data) {
    const message = { type, data };
    
    if (this.isMainWindow) {
      // メインウィンドウからディスプレイウィンドウへ
      if (this.displayWindow && !this.displayWindow.closed) {
        this.displayWindow.postMessage(message, '*');
      }
    } else {
      // ディスプレイウィンドウからメインウィンドウへ
      if (window.opener && !window.opener.closed) {
        window.opener.postMessage(message, '*');
      }
    }
  }
  
  /**
   * メッセージを処理
   */
  handleMessage(event) {
    const { type, data } = event.data;
    
    if (type && this.messageHandlers[type]) {
      this.messageHandlers[type](data);
    }
  }
}

// シングルトンインスタンスをエクスポート
export const windowCommunicator = new WindowCommunicator();
```

## 完成版の機能一覧

この修正により、クロマキー配信に最適化された以下の機能を持つManzAI Studioが完成します：

1. **クロマキー対応表示モード**
   - 専用の表示ウィンドウ（UIなし、背景色のみ）
   - キャラクター表示に特化したモード
   - フルスクリーン対応

2. **音声出力デバイス選択**
   - 複数のオーディオデバイスから選択可能
   - 設定の保存と復元

3. **キーボードショートカット制御**
   - 再生/停止: スペース
   - 新規生成: Ctrl+N
   - 表示ウィンドウ切替: Ctrl+D
   - コントロール表示/非表示: Ctrl+H
   - フルスクリーン: F11

4. **UI表示制御**
   - 完全にUIを非表示にするモード
   - 最小限のコントロールのみ表示するモード
   - デュアルウィンドウモード（操作と表示を分離）

これらの機能により、OBSなどの配信ソフトでクロマキー合成する際に、UIが邪魔になることなく、キャラクターのみを合成できるようになります。また、複数の出力デバイスを持つ配信環境にも対応できるようになります。

## 実装スケジュール

1. **音声出力デバイス選択機能**: 3日間
2. **クロマキー対応UI設計**: 5日間
3. **アプリケーションUIの最適化**: 4日間
4. **システム統合と最終テスト**: 3日間

**合計**: 15日間（約3週間）

この追加開発により、配信用途により適したManzAI Studioとなります。




